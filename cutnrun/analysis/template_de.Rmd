---
title: DB analysis of #_MARK_# cut-and-run with #_WIDTH_# bp windows
author: Aaron Lun
date: "`r Sys.Date()`"
output:
  BiocStyle::html_document:
    fig_caption: yes
---

```{r, echo=FALSE, message=FALSE, results="hide"}
library(BiocStyle)
knitr::opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
```

# Defining the files

First we define the relevant files.

```{r}
bam.files <- c(
    #_FILES_#
)
```

We also define the conditions:

```{r}
batch <- gl(2, 4)
treatment <- rep(c("sicon", "si271", "lnacon", "lna271"), 2)
data.frame(BAM=bam.files, Batch=batch, Treatment=treatment)
```

Preparing the files for read counting:

```{r}
bam.path <- "../../bam"
bam.files <- file.path(bam.path, bam.files)
```

# Counting reads in windows

Setting up a `readParam` object for read counting.
This is paired-end data, and we remove read pairs with insert sizes above 1 kbp.
We remove duplicated read pairs or reads with quality scores below 10.
We also use the ENCODE hg38 blacklist to ignore reads in problematic regions.

```{r}
library(csaw)
library(rtracklayer)
black <- import("http://mitra.stanford.edu/kundaje/akundaje/release/blacklists/hg38-human/hg38.blacklist.bed.gz")
param <- readParam(dedup=TRUE, minq=10, discard=black, pe="both", max.frag=1000)
param
```

We then count reads into #_WIDTH_# bp windows. 
No read extension is necessary as the paired reads fully define each fragment.
The spacing is set to a quarter of the width to avoid redundant loading of highly overlapping windows.

```{r}
out <- windowCounts(bam.files, param=param, width=#_WIDTH_#,
    spacing=max(50, #_WIDTH_#/4))
out
```

# Filtering out low-abundance windows

We apply a simple background-based filter to remove the low-abundance windows.
This is done by computing the median coverage of 5 kbp bins across the genome to define the filter threshold.

```{r}
bins <- windowCounts(bam.files, param=param, width=5000, bin=TRUE)
fstat <- filterWindows(data=out, background=bins, type="global")
hist(fstat$filter, col="grey80", xlab="Log2-fold increase above background",
    ylab="Number of windows", freq=TRUE)
```

We require our windows to have at least 5-fold more intensity than expected due to background binding.

```{r}
keep <- fstat$filter >= log2(5)
summary(keep)
```

We apply this filter to our object.

```{r}
filtered <- out[keep,]
```

# Normalization for efficiency biases

## Computing TMM factors

We normalize out efficiency biases, under the assumption that most histone marking does _not_ change upon lncRNA knockdown.

```{r}
filtered <- normOffsets(filtered)
colData(filtered)[,c("totals", "norm.factors")]
```

We can create some MA plots using the larger bins to examine the normalization factors, especially relative to background.

```{r}
library(edgeR)
tmp <- asDGEList(bins)
adjc <- cpm(tmp, log=TRUE, prior.count=0.5)
average <- aveLogCPM(tmp)
norm.factors <- filtered$norm.factors

par(mfrow=c(1, 2))
for (x in 2:ncol(adjc)) {
    smoothScatter(average, adjc[,x]-adjc[,1], xlab="Average", 
        ylab=sprintf("M (%i vs 1)", x))
    abline(h=log2(norm.factors[x]/norm.factors[1]), col="red", lty=2)        
}
```

## Computing trended offsets

We take it to the next level and normalize out trended biases.

```{r}
filtered <- normOffsets(filtered, type="loess")
head(assay(filtered, "offset"))
```

We can create some MA plots to check that we've correctly removed the bias.

```{r}
library(edgeR)
tmp <- asDGEList(filtered)
adjc <- log2(tmp$counts+0.5) - tmp$offset/log(2)
average <- aveLogCPM(tmp)
par(mfrow=c(1, 2))
for (x in 2:ncol(adjc)) {
    smoothScatter(average, adjc[,x]-adjc[,1], xlab="Average", 
        ylab=sprintf("M (%i vs 1)", x))
    abline(h=0, col="red", lty=2)        
}
```

## Creating MDS plots

We can also use the adjusted log-coverage to create MDS plots.

```{r}
par(mfrow=c(1,3))
labels <- paste0(treatment, ".", batch) 
col <- c("blue", "orange", "red", "darkgreen")[as.integer(factor(treatment))]
for (x in c(1000, 10000, 100000)) {
    plotMDS(adjc, top=x, main=sprintf("Top %i windows", x),
        labels=labels, col=col)
}
```

# Modelling biological variability

Setting up the design matrix:

```{r}
design <- model.matrix(~0 + treatment + batch)
design
```

Estimating the NB dispersions:

```{r}
y <- asDGEList(filtered)
y <- estimateDisp(y, design)
y$common.dispersion
```

Examining them on a plot:

```{r}
plotBCV(y)
```

Estimating the QL dispersions:

```{r}
fit <- glmQLFit(y, design, robust=TRUE)
summary(fit$df.prior)
```

Examining them on a plot:

```{r}
plotQLDisp(fit)
```

# Testing for differential binding

We test for differential binding after siRNA treatment.

```{r}
sicon <- makeContrasts(treatmentsi271 - treatmentsicon, levels=design)
res.si <- glmQLFTest(fit, contrast=sicon)
summary(decideTests(res.si))
```

We test for differential binding after LNA treatment.

```{r}
lnacon <- makeContrasts(treatmentlna271 - treatmentlnacon, levels=design)
res.lna <- glmQLFTest(fit, contrast=lnacon)
summary(decideTests(res.lna))
```

# Saving the results

Saving the window coordinates as well as the various results.

```{r}
saveRDS(file="#_MARK_#_#_WIDTH_#.rds", list(windows=rowRanges(filtered), 
    RNAi=res.si$table, LNA=res.lna$table)) 
```

Reporting the session information

```{r}
sessionInfo()
```
